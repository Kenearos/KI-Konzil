# üöÄ PROJEKT-BLUEPRINT: "CouncilOS" (KI-Rat Baukasten)

**Dokument-Typ:** Master-Product Requirements Document (PRD) & Entwicklungs-Roadmap
**Projekt-Status:** Konzept & Architektur-Briefing f√ºr das Dev-Team

---

## üåü 1. Executive Summary: Sinn und Zweck der App
**Das Problem:** 
Aktuelle KI-Tools (wie ChatGPT) arbeiten linear. Wenn ein Nutzer ein komplexes Ergebnis will (z.B. einen perfekten Blogartikel, rechtssichere PR-Texte oder lauff√§higen Code), muss er den Output st√§ndig manuell lesen, Fehler finden und die KI in endlosen Chat-Verl√§ufen korrigieren. Das kostet Zeit und erfordert extrem gutes "Prompting".

**Die L√∂sung (Unsere App):**
Wir bauen "CouncilOS" ‚Äì eine visuelle No-Code-Plattform. Anstatt selbst mit der KI zu chatten, baut der Nutzer sich einen eigenen **"KI-Rat" (Multi-Agenten-System)**. 
Der Nutzer definiert verschiedene KI-Experten, gibt ihnen Werkzeuge (Internet, PDF-Reader) und legt per Drag & Drop fest, in welcher Reihenfolge sie Dokumente bearbeiten, kritisieren und √ºberarbeiten. 

**Der USP (Unique Selling Proposition):**
Im Gegensatz zu bestehenden Tools arbeiten unsere KIs in **Endlosschleifen (Zyklen)**. Eine Kritiker-KI kann ein Dokument so lange an die Master-KI zur√ºckweisen, bis es perfekt ist, ohne dass der Mensch eingreifen muss. Wahlweise kann der Mensch als "Vorsitzender des Rates" jeden Schritt abnicken (God-Mode / Human-in-the-Loop).

### Typische Use-Cases (Beispiele f√ºr die Devs zum Verst√§ndnis):
*   **Der Content-Rat:** Master-KI (schreibt Rohfassung) ‚û°Ô∏è Kritiker-KI (pr√ºft Fakten & SEO) ‚û°Ô∏è *[Bei Fehlern zur√ºck zur Master-KI]* ‚û°Ô∏è Lektor-KI (formatiert f√ºr Social Media).
*   **Der Programmier-Rat:** Architekt-KI (schreibt Code) ‚û°Ô∏è Tester-KI (sucht Bugs) ‚û°Ô∏è *[Bei Bugs zur√ºck zum Architekten]* ‚û°Ô∏è Doku-KI (schreibt das Readme).
*   **Der Analyse-Rat:** Researcher-KI (liest 100-seitiges PDF) ‚û°Ô∏è Analyst-KI (extrahiert Kerndaten) ‚û°Ô∏è Strategie-KI (schreibt Zusammenfassung).

---

## üèóÔ∏è 2. Die Technische Architektur (Tech-Stack)
*Liebes Dev-Team, bitte nutzt zwingend diese Technologien, da sie exakt f√ºr diesen Use-Case (zyklische Graphen, Multi-Agenten & Human-in-the-loop) gemacht sind:*

*   **KI-Orchestrierung (Das Herzst√ºck):** `LangGraph` (Python). Wir nutzen LangGraph zwingend, weil es im Gegensatz zu alten Frameworks (wie LangChain Agents) echte Zyklen (Loops) erlaubt und eine eingebaute `interrupt_before` (Pause/Human-in-the-Loop) Funktion hat.
*   **Backend-API:** `FastAPI` (Python). Kommuniziert zwischen dem Frontend und dem LangGraph-Backend via WebSockets (f√ºr Echtzeit-Updates, welcher Agent gerade arbeitet).
*   **Frontend (Das Visuelle Interface):** `React` oder `Next.js` kombiniert mit **`React Flow`**. React Flow ist der Industriestandard, um interaktive Drag & Drop Canvas-Interfaces (wie Miro oder Zapier) zu bauen.
*   **Datenbank:** `PostgreSQL` (f√ºr User-Daten und gespeicherte "Rats-Baupl√§ne" als JSON) + eine simple Vektor-DB wie `ChromaDB` (lokal) oder `Pinecone` f√ºr das PDF-Lesewerkzeug.
*   **LLMs:** Integration von `Anthropic Claude 3.5 Sonnet` (Beste Logik/Coding) und `OpenAI GPT-4o` via API.

---

## üó∫Ô∏è 3. Visueller Aufbau (UI/UX)
Das Frontend besteht aus zwei Hauptbereichen (Tabs):

### Tab A: Der "Rat-Architekt" (Setup Mode)
Ein Infinite-Canvas (Whiteboard) basierend auf React Flow.
1.  **Nodes (Agenten):** Der User zieht Boxen auf das Feld. Klickt er auf eine Box, √∂ffnet sich ein Men√º: Name, System-Prompt (Rolle), LLM-Modell, aktivierte Tools (Toggle-Schalter f√ºr Web-Suche, PDF-Reader).
2.  **Edges (Verbindungen):**
    *   *Lineare Pfeile:* Agent A gibt das Dokument stur an Agent B weiter.
    *   *Bedingte Pfeile (Conditional Edges):* Agent A entscheidet selbst (Routing). Z.B. Roter Pfeil (Zur√ºck zur √úberarbeitung) / Gr√ºner Pfeil (Weiter zum Lektor).

### Tab B: Das "Konferenzzimmer" (Execution Mode)
Hier wird der gebaute Rat live gestartet.
1.  **Eingabefeld:** Der User tippt den Start-Befehl/Prompt ein oder l√§dt ein PDF hoch.
2.  **Toggle-Switch:** "Auto-Pilot" (Durchballern im Hintergrund) vs. "God Mode" (Schritt-f√ºr-Schritt abklicken).
3.  **Live-View:** Das gebaute Diagramm aus dem Setup wird angezeigt. Der aktuell arbeitende Agent leuchtet auf/pulsiert (via WebSocket).
4.  **Approval-UI (God Mode):** Wenn der Rat pausiert, poppt ein Fenster auf: *"Agent 'Kritiker' schl√§gt vor, das Dokument an 'Master KI' zur√ºckzugeben. Grund: Zu wenig Details. [Zulassen] [√úberschreiben & Weiterleiten]"*.

---

## üìÖ 4. Die Entwicklungs-Roadmap (Meilensteine)
Wir bauen das Projekt in 4 logischen Phasen. **Wichtig f√ºr die Devs:** Wir bauen das Backend (die Logik) zuerst, bevor wir das Frontend (die bunten Boxen) malen.

### üî¥ Phase 1: Die "LangGraph" Engine (Backend MVP)
*Ziel: Beweisen, dass ein iterativer KI-Rat im Code funktioniert, bevor eine UI gebaut wird.*
*   Aufsetzen der Python-Umgebung und FastAPI.
*   Programmieren eines fixen, hardcodierten Graphen in `LangGraph`: `User Input -> Master KI -> Kritiker KI -> (Bedingung: Wenn Note < 8, zur√ºck zu Master KI. Wenn > 8, zu Schriftsteller KI)`.
*   Implementieren der `State`-Logik (Ein Dictionary, das das aktuelle Dokument und Kritikpunkte von Knoten zu Knoten reicht).
*   **Test:** Ausf√ºhrung und Best√§tigung der Schleife √ºber Terminal/Postman.

### üü° Phase 2: Der Visuelle Baukasten (Frontend MVP)
*Ziel: Das Drag & Drop Interface bauen und speichern k√∂nnen.*
*   Aufsetzen von `React` und `React Flow`.
*   Entwicklung der Custom Nodes: User k√∂nnen Boxen erstellen, benennen und Prompts eintragen.
*   Entwicklung der Verkn√ºpfungen (Edges ziehen).
*   **Der Parser:** Eine Funktion schreiben, die das grafische `React Flow` Diagramm in ein strukturiertes JSON-Format √ºbersetzt und in der PostgreSQL-Datenbank speichert.

### üü¢ Phase 3: Die Hochzeit (Frontend + Backend)
*Ziel: Die Linien auf dem Bildschirm steuern die echte KI.*
*   Das LangGraph-Backend muss nun dynamisch werden. Es liest das JSON aus Phase 2 und generiert den Graphen *on the fly* im Code.
*   Einrichten von WebSockets: Wenn LangGraph den Knoten "Master KI" betritt, wird ein Event ans Frontend geschickt, damit die Box auf dem Bildschirm gelb aufleuchtet.
*   Darstellung des finalen Text-Outputs im Frontend.

### üîµ Phase 4: Tools & God Mode (Das High-End Upgrade)
*Ziel: Die App auf Enterprise-Niveau heben.*
*   **Tool-Integration:** Anbindung von `Tavily Search API` (f√ºr Web-Suche) und einem PDF-Loader (z.B. `PyPDF` + Vector Store). Zuweisung dieser Tools an spezifische Nodes im Frontend.
*   **Human-in-the-Loop:** Nutzung der `interrupt_before` Methode von LangGraph. Das Backend pausiert und schickt den State an das Frontend. Das Frontend zeigt Buttons (Approve/Reject/Modify). Klickt der User, sendet FastAPI das Signal zur√ºck an LangGraph, um die Ausf√ºhrung fortzusetzen.

---

## üõ†Ô∏è 5. Wichtige Instruktionen an das Dev-Team (Das Datenmodell)

Das Geheimnis dieser App ist der **Global State**, der von LangGraph durch den Rat gewandert wird. Baut die `TypedDict` State-Klasse im Python-Backend ungef√§hr so auf, damit zyklische Schleifen sauber funktionieren und die KI aus vorherigen Fehlern lernt:

```python
from typing import TypedDict, Annotated, List
import operator

class CouncilState(TypedDict):
    input_topic: str              # Das Ursprungsthema/PDF des Users
    current_draft: str            # Das aktuelle Dokument, an dem gearbeitet wird
    feedback_history: List[str]   # Was Kritiker bisher angemerkt haben (damit sich Fehler in der Schleife nicht wiederholen)
    route_decision: str           # Die Entscheidung der KI (z.B. "rework" oder "approve") zur Steuerung der Edges
    messages: Annotated[list, operator.add] # Der Chatverlauf f√ºr die LLMs (System Prompts + Antworten)
    
    jede ki stelle ich ja adhoc f√ºr die aufgabe ein (auch wenn ich die speichern k√∂nnen will um eine √§hnliche aufgabe mit gleichen parametern nochmal durchlaufen lassen k√∂nnte) jede KI und die anzahl derer m√∂chte ich einzeln einstellen ggf lokale.. gf mit api und so.
